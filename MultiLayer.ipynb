{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOmfiz24+WufRf+6VshztkT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7321xBfDtND","executionInfo":{"status":"ok","timestamp":1700573165573,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sriram","userId":"17110903297067748460"}},"outputId":"8e229198-82d1-4009-8654-14d8b1e23723"},"outputs":[{"output_type":"stream","name":"stdout","text":["Final hidden weights: [[-2.74529869  4.04161058]\n"," [ 6.28943553  6.56725952]]\n","Final hidden bias: [[ 2.01222886 -0.73159857]]\n","Final output weights: [[-4.5046381 ]\n"," [ 5.21265188]]\n","Final output bias: [[-0.70525207]]\n","\n","Output from neural network after 10000 epochs: [[0.04809493]\n"," [0.49717333]\n"," [0.94592611]\n"," [0.50495757]]\n"]}],"source":["import numpy as np\n","\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","# Input datasets\n","inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","expected_output = np.array([[0], [1], [1], [0]])\n","\n","# Neural network architecture\n","inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2, 2, 1\n","\n","# Random weights and bias initialization\n","hidden_weights = np.random.uniform(size=(inputLayerNeurons, hiddenLayerNeurons))\n","hidden_bias = np.random.uniform(size=(1, hiddenLayerNeurons))\n","output_weights = np.random.uniform(size=(hiddenLayerNeurons, outputLayerNeurons))\n","output_bias = np.random.uniform(size=(1, outputLayerNeurons))\n","\n","# Training parameters\n","epochs = 10000\n","lr = 0.1\n","\n","# Training algorithm\n","for _ in range(epochs):\n","    # Forward Propagation\n","    hidden_layer_output = sigmoid(np.dot(inputs, hidden_weights) + hidden_bias)\n","    predicted_output = sigmoid(np.dot(hidden_layer_output, output_weights) + output_bias)\n","\n","    # Backpropagation\n","    error = expected_output - predicted_output\n","    d_predicted_output = error * sigmoid_derivative(predicted_output)\n","    error_hidden_layer = d_predicted_output.dot(output_weights.T)\n","    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n","\n","    # Updating Weights and Biases\n","    output_weights += np.dot(hidden_layer_output.T, d_predicted_output) * lr\n","    output_bias += np.sum(d_predicted_output, axis=0, keepdims=True) * lr\n","    hidden_weights += np.dot(inputs.T, d_hidden_layer) * lr\n","    hidden_bias += np.sum(d_hidden_layer, axis=0, keepdims=True) * lr\n","\n","# Display final weights and biases\n","print(\"Final hidden weights:\", hidden_weights)\n","print(\"Final hidden bias:\", hidden_bias)\n","print(\"Final output weights:\", output_weights)\n","print(\"Final output bias:\", output_bias)\n","\n","# Display output from the neural network after training\n","print(\"\\nOutput from neural network after {} epochs:\".format(epochs), predicted_output)\n"]},{"cell_type":"code","source":["import numpy as np\n","#np.random.seed(0)\n","def sigmoid (x):\n"," return 1/(1 + np.exp(-x))\n","def sigmoid_derivative(x):\n"," return x * (1 - x)\n","#Input datasets\n","inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n","expected_output = np.array([[0],[1],[1],[0]])\n","epochs = 10000\n","lr = 0.1\n","inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\n","#Random weights and bias initialization\n","hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n","hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n","output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n","output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n","print(\"Initial hidden weights: \",end='')\n","print(*hidden_weights)\n","print(\"Initial hidden biases: \",end='')\n","print(*hidden_bias)\n","print(\"Initial output weights: \",end='')\n","print(*output_weights)\n","print(\"Initial output biases: \",end='')\n","print(*output_bias)\n","#Training algorithm\n","for _ in range(epochs):\n","#Forward Propagation\n"," hidden_layer_activation = np.dot(inputs,hidden_weights)\n"," hidden_layer_activation += hidden_bias\n"," hidden_layer_output = sigmoid(hidden_layer_activation)\n"," output_layer_activation = np.dot(hidden_layer_output,output_weights)\n"," output_layer_activation += output_bias\n"," predicted_output = sigmoid(output_layer_activation)\n","#Backpropagation\n"," error = expected_output - predicted_output\n"," d_predicted_output = error * sigmoid_derivative(predicted_output)\n"," error_hidden_layer = d_predicted_output.dot(output_weights.T)\n"," d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n","#Updating Weights and Biases\n"," output_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n"," output_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n"," hidden_weights += inputs.T.dot(d_hidden_layer) * lr\n"," hidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n","print(\"Final hidden weights: \",end='')\n","print(*hidden_weights)\n","print(\"Final hidden bias: \",end='')\n","print(*hidden_bias)\n","print(\"Final output weights: \",end='')\n","print(*output_weights)\n","print(\"Final output bias: \",end='')\n","print(*output_bias)\n","print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n","print(*predicted_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C65f9_z7EGA5","executionInfo":{"status":"ok","timestamp":1700573351511,"user_tz":-330,"elapsed":1126,"user":{"displayName":"Sriram","userId":"17110903297067748460"}},"outputId":"06e25ff0-8051-4199-f54c-73b812f62007"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial hidden weights: [0.29536945 0.42834439] [0.05060655 0.64332413]\n","Initial hidden biases: [0.54945496 0.55598398]\n","Initial output weights: [0.07155487] [0.55649169]\n","Initial output biases: [0.34004756]\n","Final hidden weights: [3.65309696 5.89583472] [3.63576931 5.80474932]\n","Final hidden bias: [-5.57998648 -2.44148321]\n","Final output weights: [-8.15691147] [7.47036729]\n","Final output bias: [-3.34094103]\n","\n","Output from neural network after 10,000 epochs: [0.05877915] [0.94574118] [0.94602362] [0.05854959]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","# R matrix\n","R = np.matrix([[-1, -1, -1, -1, 0, -1],\n","               [-1, -1, -1, 0, -1, 100],\n","               [-1, -1, -1, 0, -1, -1],\n","               [-1, 0, 0, -1, 0, -1],\n","               [-1, 0, 0, -1, -1, 100],\n","               [-1, 0, -1, -1, 0, 100]])\n","\n","# Q matrix\n","Q = np.matrix(np.zeros([6, 6]))\n","\n","# Gamma (learning parameter).\n","gamma = 0.8\n","\n","# Initial state. (Usually chosen at random)\n","initial_state = 1\n","\n","# This function returns all available actions in the state given as an argument\n","def available_actions(state):\n","    current_state_row = R[state, ]\n","    av_act = np.where(current_state_row >= 0)[1]\n","    return av_act\n","\n","# Get available actions in the current state\n","available_act = available_actions(initial_state)\n","\n","# This function chooses at random which action to be performed within the range\n","# of all the available actions.\n","def sample_next_action(available_actions_range):\n","    next_action = int(np.random.choice(available_actions_range, 1))\n","    return next_action\n","\n","# Sample next action to be performed\n","action = sample_next_action(available_act)\n","\n","# This function updates the Q matrix according to the path selected and the Q\n","# learning algorithm\n","def update(current_state, action, gamma):\n","    max_index = np.where(Q[action, ] == np.max(Q[action, ]))[1]\n","\n","    if max_index.shape[0] > 1:\n","        max_index = int(np.random.choice(max_index, size=1))\n","    else:\n","        max_index = int(max_index)\n","\n","    max_value = Q[action, max_index]\n","\n","    # Q learning formula\n","    Q[current_state, action] = R[current_state, action] + gamma * max_value\n","\n","# Training\n","# Train over 10,000 iterations. (Re-iterate the process above).\n","for i in range(10000):\n","    current_state = np.random.randint(0, int(Q.shape[0]))\n","    available_act = available_actions(current_state)\n","    action = sample_next_action(available_act)\n","    update(current_state, action, gamma)\n","\n","# Normalize the \"trained\" Q matrix\n","print(\"Trained Q matrix:\")\n","print(Q / np.max(Q) * 100)\n","\n","# Testing\n","# Goal state = 5\n","# Best sequence path starting from 2 -> 2, 3, 1, 5\n","current_state = 2\n","steps = [current_state]\n","while current_state != 5:\n","    next_step_index = np.where(Q[current_state, ] == np.max(Q[current_state, ]))[1]\n","\n","    if next_step_index.shape[0] > 1:\n","        next_step_index = int(np.random.choice(next_step_index, size=1))\n","    else:\n","        next_step_index = int(next_step_index)\n","\n","    steps.append(next_step_index)\n","    current_state = next_step_index\n","\n","# Print selected sequence of steps\n","print(\"Selected path:\")\n","print(steps)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bZ9a0On5E0x6","executionInfo":{"status":"ok","timestamp":1700573556726,"user_tz":-330,"elapsed":2145,"user":{"displayName":"Sriram","userId":"17110903297067748460"}},"outputId":"d82179aa-ec22-444b-c3a8-70fb334e5fd7"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Trained Q matrix:\n","[[  0.    0.    0.    0.   80.    0. ]\n"," [  0.    0.    0.   64.    0.  100. ]\n"," [  0.    0.    0.   64.    0.    0. ]\n"," [  0.   80.   51.2   0.   80.    0. ]\n"," [  0.   80.   51.2   0.    0.  100. ]\n"," [  0.   80.    0.    0.   80.  100. ]]\n","Selected path:\n","[2, 3, 4, 5]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","# R matrix\n","R = np.matrix([[-1, -1, -1, -1, 0, -1],\n","               [-1, -1, -1, 0, -1, 100],\n","               [-1, -1, -1, 0, -1, -1],\n","               [-1, 0, 0, -1, 0, -1],\n","               [-1, 0, 0, -1, -1, 100],\n","               [-1, 0, -1, -1, 0, 100]])\n","\n","# Q matrix\n","Q = np.zeros_like(R, dtype=float)\n","\n","# Gamma (learning parameter).\n","gamma = 0.8\n","\n","# Initial state. (Usually chosen at random)\n","initial_state = 1\n","\n","# This function returns all available actions in the state given as an argument\n","def available_actions(state):\n","    return np.where(R[state] >= 0)[1]\n","\n","# This function chooses at random which action to be performed within the range\n","# of all the available actions.\n","def sample_next_action(available_actions_range):\n","    return int(np.random.choice(available_actions_range))\n","\n","# Training\n","# Train over 10,000 iterations. (Re-iterate the process above).\n","for _ in range(10000):\n","    current_state = np.random.randint(Q.shape[0])\n","    available_act = available_actions(current_state)\n","    action = sample_next_action(available_act)\n","    max_index = np.argmax(Q[action])\n","    max_value = Q[action, max_index]\n","    Q[current_state, action] = R[current_state, action] + gamma * max_value\n","\n","# Normalize the \"trained\" Q matrix\n","print(\"Trained Q matrix:\")\n","print(Q / np.max(Q) * 100)\n","\n","# Testing\n","# Goal state = 5\n","# Best sequence path starting from 2 -> 2, 3, 1, 5\n","current_state = 2\n","steps = [current_state]\n","while current_state != 5:\n","    next_step_index = np.argmax(Q[current_state])\n","    steps.append(next_step_index)\n","    current_state = next_step_index\n","\n","# Print selected sequence of steps\n","print(\"Selected path:\")\n","print(steps)\n"],"metadata":{"id":"WsSqBhfzGp_j","executionInfo":{"status":"ok","timestamp":1700573918603,"user_tz":-330,"elapsed":1645,"user":{"displayName":"Sriram","userId":"17110903297067748460"}},"outputId":"7c963fd9-ef11-4f2d-d16c-a271be31a32b","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Trained Q matrix:\n","[[  0.    0.    0.    0.   80.    0. ]\n"," [  0.    0.    0.   64.    0.  100. ]\n"," [  0.    0.    0.   64.    0.    0. ]\n"," [  0.   80.   51.2   0.   80.    0. ]\n"," [  0.   80.   51.2   0.    0.  100. ]\n"," [  0.   80.    0.    0.   80.  100. ]]\n","Selected path:\n","[2, 3, 1, 5]\n"]}]}]}